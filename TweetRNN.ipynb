{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c623cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b69c6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # vocabulary size\n",
    "max_len = 100         # max length for padding\n",
    "# Load data\n",
    "tweets = pd.read_csv(\"Tweets.csv\")\n",
    "tweet = tweets.dropna(subset=['text'])\n",
    "tweet['negativereason_confidence']=tweet['negativereason_confidence'].fillna(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7ae5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y\n",
    "X = tweet['text']\n",
    "y = tweet['negativereason_confidence']\n",
    "\n",
    "# Tokenize the entire dataset (fit tokenizer on all texts)\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd182ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6841bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences and labels into train and test sets\n",
    "X_train_seq, X_test_seq, y_train, y_test = train_test_split(\n",
    "    sequences, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a67593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (11712, 100), Training labels shape: (11712,)\n",
      "Testing data shape: (2928, 100), Testing labels shape: (2928,)\n"
     ]
    }
   ],
   "source": [
    "# Pad the token sequences so they have the same length\n",
    "X_train = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad8f60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Simple RNN\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features,128,input_length=max_len)) ## Embedding Layers\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6585655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10f9339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an instance of EarlyStopping Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20a921d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "293/293 [==============================] - 9s 26ms/step - loss: 0.6508 - accuracy: 0.2499 - val_loss: 0.6294 - val_accuracy: 0.2582\n",
      "Epoch 2/10\n",
      "293/293 [==============================] - 8s 26ms/step - loss: 0.6116 - accuracy: 0.2935 - val_loss: 0.6326 - val_accuracy: 0.2629\n",
      "Epoch 3/10\n",
      "293/293 [==============================] - 8s 28ms/step - loss: 0.5746 - accuracy: 0.3127 - val_loss: 0.6473 - val_accuracy: 0.2539\n",
      "Epoch 4/10\n",
      "293/293 [==============================] - 7s 25ms/step - loss: 0.5400 - accuracy: 0.3212 - val_loss: 0.6651 - val_accuracy: 0.2505\n",
      "Epoch 5/10\n",
      "293/293 [==============================] - 7s 24ms/step - loss: 0.5132 - accuracy: 0.3267 - val_loss: 0.6871 - val_accuracy: 0.2450\n",
      "Epoch 6/10\n",
      "293/293 [==============================] - 7s 24ms/step - loss: 0.4948 - accuracy: 0.3292 - val_loss: 0.7125 - val_accuracy: 0.2501\n"
     ]
    }
   ],
   "source": [
    "## Train the model with early stopping\n",
    "history=model.fit(\n",
    "    X_train,y_train,epochs=10,batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82d23b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus-pc\\Documents\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "## Save model file\n",
    "model.save('TweeterSentimentAnalysis.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
